{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, sys,os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, \"..\")\n",
    "import random\n",
    "import src.utils.dtw as dtw\n",
    "import src.models.augmentations as augmentations\n",
    "import src.visualization.visualize as visualize\n",
    "import src.utils.data_extraction as extractions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitud de la serie de tiempo a generar\n",
    "TIME_STEPS = 500\n",
    "\n",
    "# Dimensión de entrada para el Generador\n",
    "NOISE_DIM = 20\n",
    "\n",
    "# Número de unidades en las capas ocultas\n",
    "HIDDEN_UNITS = 128\n",
    "\n",
    "# Tasa de aprendizaje para el optimizador\n",
    "LEARNING_RATE = 0.0002\n",
    "\n",
    "# Número de iteraciones de entrenamiento\n",
    "EPOCHS = 10000\n",
    "\n",
    "# Tamaño del lote para el entrenamiento del GAN\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Función para generar ruido (entrada del Generador)\n",
    "def generate_noise(batch_size, dim):\n",
    "    return np.random.normal(0, 1, size=(batch_size, dim))\n",
    "\n",
    "# Función para generar datos de series de tiempo reales (no usada en este caso)\n",
    "def generate_real_data(batch_size):\n",
    "    return np.random.uniform(-1, 1, size=(batch_size, TIME_STEPS, 1))\n",
    "\n",
    "# Función para mostrar algunas series de tiempo generadas\n",
    "def plot_generated_time_series(samples):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(samples.shape[0]):\n",
    "        plt.plot(samples[i], linewidth=1)\n",
    "    plt.title('Series de Tiempo Generadas por el GAN')\n",
    "    plt.xlabel('Tiempo')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el Generador\n",
    "generator = Sequential([\n",
    "    Dense(units=HIDDEN_UNITS, input_dim=NOISE_DIM),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(units=TIME_STEPS * 1, activation='tanh'),\n",
    "    Reshape((TIME_STEPS, 1))\n",
    "])\n",
    "\n",
    "# Construir el Discriminador\n",
    "discriminator = Sequential([\n",
    "    Flatten(input_shape=(TIME_STEPS, 1)),\n",
    "    Dense(units=HIDDEN_UNITS),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el Generador\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=LEARNING_RATE))\n",
    "\n",
    "# Congelar el Discriminador para el entrenamiento del GAN\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Compilar el GAN (Generador + Discriminador)\n",
    "gan_input = tf.keras.Input(shape=(NOISE_DIM,))\n",
    "generated_series = generator(gan_input)\n",
    "gan_output = discriminator(generated_series)\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=LEARNING_RATE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el GAN\n",
    "def train_gan(X_train, epochs, batch_size, sample_interval=100):\n",
    "    for epoch in range(epochs):\n",
    "        # ---------------------\n",
    "        #  Entrenar Discriminador\n",
    "        # ---------------------\n",
    "\n",
    "        # Seleccionar un lote aleatorio de datos reales\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_series = X_train[idx]\n",
    "\n",
    "        # Generar ruido como entrada del Generador\n",
    "        noise = generate_noise(batch_size, NOISE_DIM)\n",
    "\n",
    "        # Generar un lote de series de tiempo falsas con el Generador\n",
    "        generated_series = generator.predict(noise)\n",
    "\n",
    "        # Entrenar el Discriminador\n",
    "        d_loss_real = discriminator.train_on_batch(real_series, np.ones((batch_size, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_series, np.zeros((batch_size, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Entrenar Generador\n",
    "        # ---------------------\n",
    "\n",
    "        # Generar ruido como entrada del GAN\n",
    "        noise = generate_noise(batch_size, NOISE_DIM)\n",
    "\n",
    "        # Entrenar el Generador (el Discriminador se mantiene fijo)\n",
    "        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # Mostrar el progreso del entrenamiento\n",
    "        if epoch % sample_interval == 0:\n",
    "            print(f'Epoch {epoch}, Discriminador Loss: {d_loss}, Generador Loss: {g_loss}')\n",
    "            # Generar y mostrar ejemplos de series de tiempo generadas\n",
    "            samples = generator.predict(generate_noise(5, NOISE_DIM))\n",
    "            plot_generated_time_series(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = pd.read_json('../data/processed/realData.json', orient='records', lines=True)\n",
    "# Filtrar las series de tiempo por clase\n",
    "healthy_cop_x = timeSeries[timeSeries['class'] == 'Healthy']['cop_x']\n",
    "neuropathic_cop_x = timeSeries[timeSeries['class'] == 'Neuropathic']['cop_x']\n",
    "diabetic_cop_x = timeSeries[timeSeries['class'] == 'Diabetic']['cop_x']\n",
    "\n",
    "healthy_cop_y = timeSeries[timeSeries['class'] == 'Healthy']['cop_y']\n",
    "neuropathic_cop_y = timeSeries[timeSeries['class'] == 'Neuropathic']['cop_y']\n",
    "diabetic_cop_y = timeSeries[timeSeries['class'] == 'Diabetic']['cop_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos de ejemplo para entrenar el GAN\n",
    "X_train = healthy_cop_x  # En este caso, generamos datos aleatorios uniformemente distribuidos\n",
    "\n",
    "# Normalizar los datos para que estén entre -1 y 1\n",
    "X_train = (X_train - 0.5) / 0.5\n",
    "\n",
    "# Entrenar el GAN\n",
    "train_gan(X_train, EPOCHS, BATCH_SIZE)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
