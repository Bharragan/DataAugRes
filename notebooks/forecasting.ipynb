{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, sys,os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/processed/realData.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/processed/realData.json', orient='records', lines=True)\n",
    "# Convertir las cadenas en listas de números\n",
    "df['cop_x'] = df['cop_x'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "df['cop_y'] = df['cop_y'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "\n",
    "# Convertir las series de tiempo a arrays numpy\n",
    "X_cop_x = np.array(df['cop_x'].tolist())\n",
    "X_cop_y = np.array(df['cop_y'].tolist())\n",
    "X = np.stack((X_cop_x, X_cop_y), axis=-1)  # Combinar en una sola entrada con 2 canales\n",
    "\n",
    "# Convertir las etiquetas a números\n",
    "label_map = {'Healthy': 0, 'Diabetic': 1, 'Neuropathic': 2}\n",
    "y = df['class'].map(label_map).values\n",
    "\n",
    "# Crear etiquetas para nivel 1 y nivel 2\n",
    "level1_labels = (y > 0).astype(int)  # 0: Healthy, 1: Diabetic (incluye Neuropathic)\n",
    "level2_labels = (y == 2).astype(int)  # 0: Diabetic sin neuropatía, 1: Neuropathic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear etiquetas para nivel 1 y nivel 2 para el conjunto de prueba\n",
    "level1_labels_train = (y_train > 0).astype(int)\n",
    "level2_labels_train = (y_train == 2).astype(int)\n",
    "\n",
    "level1_labels_test = (y_test > 0).astype(int)\n",
    "level2_labels_test = (y_test == 2).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ level1_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ level2_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m960\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ level1_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ level2_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,994</span> (300.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,994\u001b[0m (300.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,098</span> (297.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,098\u001b[0m (297.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    act1 = Activation('relu')(bn1)\n",
    "\n",
    "    conv2 = Conv1D(filters, kernel_size, strides=1, padding='same')(act1)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "\n",
    "    if stride != 1:\n",
    "        x = Conv1D(filters, 1, strides=stride, padding='same')(x)\n",
    "    shortcut = Add()([x, bn2])\n",
    "    output = Activation('relu')(shortcut)\n",
    "    return output\n",
    "\n",
    "input_shape = X.shape[1:]\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv1D(64, 7, strides=2, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Salida para nivel 1 (Healthy vs Diabetic)\n",
    "level1_output = Dense(1, activation='sigmoid', name='level1_output')(x)\n",
    "\n",
    "# Salida para nivel 2 (Diabetic sin neuropatía vs Neuropathic)\n",
    "level2_output = Dense(1, activation='sigmoid', name='level2_output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[level1_output, level2_output])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'level1_output': 'binary_crossentropy', 'level2_output': 'binary_crossentropy'},\n",
    "              metrics={'level1_output': 'accuracy', 'level2_output': 'accuracy'})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - level1_output_accuracy: 0.4422 - level2_output_accuracy: 0.5500 - loss: 1.6860 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6714 - val_loss: 1.3209\n",
      "Epoch 2/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - level1_output_accuracy: 0.8468 - level2_output_accuracy: 0.6334 - loss: 1.0451 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6000 - val_loss: 1.2766\n",
      "Epoch 3/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - level1_output_accuracy: 0.8338 - level2_output_accuracy: 0.7032 - loss: 1.0448 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5857 - val_loss: 1.2708\n",
      "Epoch 4/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - level1_output_accuracy: 0.8124 - level2_output_accuracy: 0.6674 - loss: 1.0328 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5857 - val_loss: 1.2887\n",
      "Epoch 5/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - level1_output_accuracy: 0.8447 - level2_output_accuracy: 0.7043 - loss: 0.9380 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2898\n",
      "Epoch 6/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - level1_output_accuracy: 0.8005 - level2_output_accuracy: 0.7052 - loss: 1.0193 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5143 - val_loss: 1.2925\n",
      "Epoch 7/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - level1_output_accuracy: 0.8277 - level2_output_accuracy: 0.6715 - loss: 0.9651 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5429 - val_loss: 1.2723\n",
      "Epoch 8/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - level1_output_accuracy: 0.8293 - level2_output_accuracy: 0.7428 - loss: 0.9255 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.5286 - val_loss: 1.2966\n",
      "Epoch 9/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.8137 - level2_output_accuracy: 0.6975 - loss: 0.9210 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5143 - val_loss: 1.2727\n",
      "Epoch 10/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - level1_output_accuracy: 0.8498 - level2_output_accuracy: 0.7086 - loss: 0.8907 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5429 - val_loss: 1.2570\n",
      "Epoch 11/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - level1_output_accuracy: 0.8712 - level2_output_accuracy: 0.6838 - loss: 0.9242 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5286 - val_loss: 1.2473\n",
      "Epoch 12/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - level1_output_accuracy: 0.8580 - level2_output_accuracy: 0.7300 - loss: 0.8557 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.5286 - val_loss: 1.2384\n",
      "Epoch 13/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - level1_output_accuracy: 0.8613 - level2_output_accuracy: 0.6938 - loss: 0.9056 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.5429 - val_loss: 1.2528\n",
      "Epoch 14/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - level1_output_accuracy: 0.8372 - level2_output_accuracy: 0.7178 - loss: 0.8723 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2102\n",
      "Epoch 15/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - level1_output_accuracy: 0.8524 - level2_output_accuracy: 0.7829 - loss: 0.8293 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.5286 - val_loss: 1.2241\n",
      "Epoch 16/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - level1_output_accuracy: 0.8336 - level2_output_accuracy: 0.8044 - loss: 0.8533 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2112\n",
      "Epoch 17/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - level1_output_accuracy: 0.8879 - level2_output_accuracy: 0.7620 - loss: 0.7752 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.5429 - val_loss: 1.1908\n",
      "Epoch 18/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - level1_output_accuracy: 0.8302 - level2_output_accuracy: 0.7815 - loss: 0.8181 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.4714 - val_loss: 1.2554\n",
      "Epoch 19/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - level1_output_accuracy: 0.8386 - level2_output_accuracy: 0.7307 - loss: 0.8783 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5143 - val_loss: 1.2318\n",
      "Epoch 20/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - level1_output_accuracy: 0.8366 - level2_output_accuracy: 0.7206 - loss: 0.8877 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.4571 - val_loss: 1.2216\n",
      "Epoch 21/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - level1_output_accuracy: 0.9054 - level2_output_accuracy: 0.7707 - loss: 0.7493 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5000 - val_loss: 1.4116\n",
      "Epoch 22/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - level1_output_accuracy: 0.8621 - level2_output_accuracy: 0.8179 - loss: 0.7442 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.4714 - val_loss: 1.3691\n",
      "Epoch 23/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - level1_output_accuracy: 0.8424 - level2_output_accuracy: 0.7196 - loss: 0.8484 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5143 - val_loss: 1.3734\n",
      "Epoch 24/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - level1_output_accuracy: 0.8521 - level2_output_accuracy: 0.7329 - loss: 0.7830 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.4857 - val_loss: 1.2791\n",
      "Epoch 25/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.8716 - level2_output_accuracy: 0.7890 - loss: 0.7343 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5429 - val_loss: 1.2302\n",
      "Epoch 26/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - level1_output_accuracy: 0.8750 - level2_output_accuracy: 0.7557 - loss: 0.7563 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.4714 - val_loss: 1.2952\n",
      "Epoch 27/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.8702 - level2_output_accuracy: 0.7784 - loss: 0.7775 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5286 - val_loss: 1.3463\n",
      "Epoch 28/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.8928 - level2_output_accuracy: 0.8635 - loss: 0.6512 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6000 - val_loss: 1.2477\n",
      "Epoch 29/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.8702 - level2_output_accuracy: 0.7679 - loss: 0.7417 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.5143 - val_loss: 1.5625\n",
      "Epoch 30/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - level1_output_accuracy: 0.8917 - level2_output_accuracy: 0.7917 - loss: 0.6814 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.5857 - val_loss: 1.3549\n",
      "Epoch 31/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.9060 - level2_output_accuracy: 0.7929 - loss: 0.6777 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.5286 - val_loss: 1.3540\n",
      "Epoch 32/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - level1_output_accuracy: 0.8969 - level2_output_accuracy: 0.8441 - loss: 0.6206 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.5000 - val_loss: 1.2939\n",
      "Epoch 33/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.8969 - level2_output_accuracy: 0.8847 - loss: 0.6054 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.4143 - val_loss: 1.3942\n",
      "Epoch 34/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.8957 - level2_output_accuracy: 0.8430 - loss: 0.6188 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6000 - val_loss: 1.3420\n",
      "Epoch 35/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.8978 - level2_output_accuracy: 0.8534 - loss: 0.5996 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.4857 - val_loss: 1.3250\n",
      "Epoch 36/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - level1_output_accuracy: 0.9217 - level2_output_accuracy: 0.8617 - loss: 0.5917 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.5429 - val_loss: 1.3505\n",
      "Epoch 37/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.8990 - level2_output_accuracy: 0.8275 - loss: 0.6198 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5714 - val_loss: 1.3083\n",
      "Epoch 38/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.8787 - level2_output_accuracy: 0.8806 - loss: 0.5892 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5714 - val_loss: 1.3588\n",
      "Epoch 39/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.9272 - level2_output_accuracy: 0.8579 - loss: 0.5378 - val_level1_output_accuracy: 0.7000 - val_level2_output_accuracy: 0.5143 - val_loss: 1.5340\n",
      "Epoch 40/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - level1_output_accuracy: 0.8843 - level2_output_accuracy: 0.8094 - loss: 0.5991 - val_level1_output_accuracy: 0.5429 - val_level2_output_accuracy: 0.5286 - val_loss: 1.7855\n",
      "Epoch 41/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - level1_output_accuracy: 0.9084 - level2_output_accuracy: 0.8837 - loss: 0.5236 - val_level1_output_accuracy: 0.6857 - val_level2_output_accuracy: 0.5429 - val_loss: 1.5571\n",
      "Epoch 42/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - level1_output_accuracy: 0.9145 - level2_output_accuracy: 0.8966 - loss: 0.5114 - val_level1_output_accuracy: 0.7429 - val_level2_output_accuracy: 0.5571 - val_loss: 1.4545\n",
      "Epoch 43/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - level1_output_accuracy: 0.9330 - level2_output_accuracy: 0.8503 - loss: 0.5419 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.4857 - val_loss: 2.1640\n",
      "Epoch 44/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.9305 - level2_output_accuracy: 0.8750 - loss: 0.5524 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.5571 - val_loss: 1.5741\n",
      "Epoch 45/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.8835 - level2_output_accuracy: 0.8641 - loss: 0.5693 - val_level1_output_accuracy: 0.7000 - val_level2_output_accuracy: 0.5571 - val_loss: 1.5288\n",
      "Epoch 46/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - level1_output_accuracy: 0.9388 - level2_output_accuracy: 0.8447 - loss: 0.5009 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6429 - val_loss: 1.3472\n",
      "Epoch 47/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.8972 - level2_output_accuracy: 0.8496 - loss: 0.5058 - val_level1_output_accuracy: 0.8429 - val_level2_output_accuracy: 0.5857 - val_loss: 1.4686\n",
      "Epoch 48/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.9243 - level2_output_accuracy: 0.9138 - loss: 0.4741 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5571 - val_loss: 1.3839\n",
      "Epoch 49/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.9331 - level2_output_accuracy: 0.9456 - loss: 0.4134 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6000 - val_loss: 1.3575\n",
      "Epoch 50/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - level1_output_accuracy: 0.9333 - level2_output_accuracy: 0.8743 - loss: 0.4652 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.6143 - val_loss: 1.4296\n",
      "Epoch 51/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - level1_output_accuracy: 0.9610 - level2_output_accuracy: 0.9151 - loss: 0.4210 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5857 - val_loss: 1.5585\n",
      "Epoch 52/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.9615 - level2_output_accuracy: 0.9121 - loss: 0.3902 - val_level1_output_accuracy: 0.7286 - val_level2_output_accuracy: 0.6000 - val_loss: 1.5306\n",
      "Epoch 53/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - level1_output_accuracy: 0.9392 - level2_output_accuracy: 0.9004 - loss: 0.4438 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6143 - val_loss: 1.5075\n",
      "Epoch 54/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.9548 - level2_output_accuracy: 0.9472 - loss: 0.3775 - val_level1_output_accuracy: 0.6286 - val_level2_output_accuracy: 0.6000 - val_loss: 1.7320\n",
      "Epoch 55/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - level1_output_accuracy: 0.9281 - level2_output_accuracy: 0.9308 - loss: 0.4019 - val_level1_output_accuracy: 0.6000 - val_level2_output_accuracy: 0.5714 - val_loss: 2.0193\n",
      "Epoch 56/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.9113 - level2_output_accuracy: 0.9087 - loss: 0.4775 - val_level1_output_accuracy: 0.8429 - val_level2_output_accuracy: 0.5857 - val_loss: 1.6716\n",
      "Epoch 57/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - level1_output_accuracy: 0.9558 - level2_output_accuracy: 0.9360 - loss: 0.4090 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6571 - val_loss: 1.2710\n",
      "Epoch 58/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - level1_output_accuracy: 0.9271 - level2_output_accuracy: 0.9078 - loss: 0.4284 - val_level1_output_accuracy: 0.7429 - val_level2_output_accuracy: 0.5714 - val_loss: 2.0300\n",
      "Epoch 59/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.8882 - level2_output_accuracy: 0.8964 - loss: 0.4555 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5857 - val_loss: 1.4675\n",
      "Epoch 60/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.9430 - level2_output_accuracy: 0.9073 - loss: 0.3930 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6286 - val_loss: 1.3782\n",
      "Epoch 61/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - level1_output_accuracy: 0.9261 - level2_output_accuracy: 0.8539 - loss: 0.5258 - val_level1_output_accuracy: 0.6429 - val_level2_output_accuracy: 0.5857 - val_loss: 1.6364\n",
      "Epoch 62/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - level1_output_accuracy: 0.9095 - level2_output_accuracy: 0.8875 - loss: 0.4850 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5571 - val_loss: 1.3506\n",
      "Epoch 63/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.9510 - level2_output_accuracy: 0.9254 - loss: 0.3780 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6286 - val_loss: 1.4315\n",
      "Epoch 64/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - level1_output_accuracy: 0.9355 - level2_output_accuracy: 0.9729 - loss: 0.3407 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5571 - val_loss: 1.3767\n",
      "Epoch 65/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.9484 - level2_output_accuracy: 0.9524 - loss: 0.3340 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6286 - val_loss: 1.3221\n",
      "Epoch 66/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - level1_output_accuracy: 0.9717 - level2_output_accuracy: 0.9277 - loss: 0.3321 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6143 - val_loss: 1.3461\n",
      "Epoch 67/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.9768 - level2_output_accuracy: 0.9543 - loss: 0.3183 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.5714 - val_loss: 1.4177\n",
      "Epoch 68/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.9656 - level2_output_accuracy: 0.9465 - loss: 0.3036 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6571 - val_loss: 1.3122\n",
      "Epoch 69/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.9596 - level2_output_accuracy: 0.9563 - loss: 0.2632 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.6000 - val_loss: 1.3778\n",
      "Epoch 70/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - level1_output_accuracy: 0.9635 - level2_output_accuracy: 0.9572 - loss: 0.2820 - val_level1_output_accuracy: 0.7429 - val_level2_output_accuracy: 0.5571 - val_loss: 1.9351\n",
      "Epoch 71/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.9792 - level2_output_accuracy: 0.9467 - loss: 0.3103 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.6286 - val_loss: 1.6318\n",
      "Epoch 72/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - level1_output_accuracy: 0.9866 - level2_output_accuracy: 0.9378 - loss: 0.3022 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6429 - val_loss: 1.3041\n",
      "Epoch 73/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - level1_output_accuracy: 0.9650 - level2_output_accuracy: 0.9730 - loss: 0.2363 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.6000 - val_loss: 1.7132\n",
      "Epoch 74/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.9448 - level2_output_accuracy: 0.9243 - loss: 0.3685 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.6000 - val_loss: 1.6632\n",
      "Epoch 75/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - level1_output_accuracy: 0.9803 - level2_output_accuracy: 0.9377 - loss: 0.2877 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6143 - val_loss: 1.4884\n",
      "Epoch 76/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - level1_output_accuracy: 0.9741 - level2_output_accuracy: 0.9657 - loss: 0.2551 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6286 - val_loss: 1.4029\n",
      "Epoch 77/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - level1_output_accuracy: 0.9688 - level2_output_accuracy: 0.9673 - loss: 0.2818 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6286 - val_loss: 1.7131\n",
      "Epoch 78/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.9818 - level2_output_accuracy: 0.9387 - loss: 0.2727 - val_level1_output_accuracy: 0.8571 - val_level2_output_accuracy: 0.6143 - val_loss: 1.2890\n",
      "Epoch 79/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - level1_output_accuracy: 0.9682 - level2_output_accuracy: 0.9320 - loss: 0.3101 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5571 - val_loss: 1.8016\n",
      "Epoch 80/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - level1_output_accuracy: 0.9904 - level2_output_accuracy: 0.9512 - loss: 0.2503 - val_level1_output_accuracy: 0.8143 - val_level2_output_accuracy: 0.6000 - val_loss: 1.7480\n",
      "Epoch 81/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - level1_output_accuracy: 0.9611 - level2_output_accuracy: 0.9761 - loss: 0.2524 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6000 - val_loss: 1.8594\n",
      "Epoch 82/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - level1_output_accuracy: 0.9715 - level2_output_accuracy: 0.9634 - loss: 0.2490 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.5571 - val_loss: 1.7510\n",
      "Epoch 83/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - level1_output_accuracy: 0.9858 - level2_output_accuracy: 0.9437 - loss: 0.3006 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.6143 - val_loss: 1.6171\n",
      "Epoch 84/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.9806 - level2_output_accuracy: 0.9672 - loss: 0.1966 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5857 - val_loss: 1.8158\n",
      "Epoch 85/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - level1_output_accuracy: 0.9885 - level2_output_accuracy: 0.9877 - loss: 0.1925 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6286 - val_loss: 1.6065\n",
      "Epoch 86/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - level1_output_accuracy: 0.9965 - level2_output_accuracy: 0.9989 - loss: 0.1557 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.6143 - val_loss: 1.7086\n",
      "Epoch 87/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.9742 - level2_output_accuracy: 0.9724 - loss: 0.1855 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.6286 - val_loss: 1.5510\n",
      "Epoch 88/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - level1_output_accuracy: 0.9908 - level2_output_accuracy: 0.9744 - loss: 0.1702 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6286 - val_loss: 1.5772\n",
      "Epoch 89/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - level1_output_accuracy: 0.9972 - level2_output_accuracy: 0.9887 - loss: 0.1541 - val_level1_output_accuracy: 0.7286 - val_level2_output_accuracy: 0.5857 - val_loss: 2.0030\n",
      "Epoch 90/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - level1_output_accuracy: 0.9911 - level2_output_accuracy: 0.9948 - loss: 0.1705 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.5429 - val_loss: 2.5740\n",
      "Epoch 91/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - level1_output_accuracy: 0.9883 - level2_output_accuracy: 0.9647 - loss: 0.1899 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.6143 - val_loss: 1.7240\n",
      "Epoch 92/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - level1_output_accuracy: 0.9861 - level2_output_accuracy: 0.9465 - loss: 0.2046 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6143 - val_loss: 2.5327\n",
      "Epoch 93/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.9743 - level2_output_accuracy: 0.9588 - loss: 0.2265 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6429 - val_loss: 1.7657\n",
      "Epoch 94/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.9816 - level2_output_accuracy: 0.9600 - loss: 0.2299 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.6000 - val_loss: 2.8294\n",
      "Epoch 95/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - level1_output_accuracy: 0.9480 - level2_output_accuracy: 0.9667 - loss: 0.2520 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.6429 - val_loss: 1.8666\n",
      "Epoch 96/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.9928 - level2_output_accuracy: 0.9517 - loss: 0.2013 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.5857 - val_loss: 1.6633\n",
      "Epoch 97/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - level1_output_accuracy: 0.9908 - level2_output_accuracy: 0.9815 - loss: 0.1568 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5857 - val_loss: 2.2482\n",
      "Epoch 98/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.9984 - level2_output_accuracy: 0.9901 - loss: 0.1528 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.6286 - val_loss: 1.8538\n",
      "Epoch 99/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - level1_output_accuracy: 0.9869 - level2_output_accuracy: 0.9454 - loss: 0.2084 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6571 - val_loss: 1.6239\n",
      "Epoch 100/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.9779 - level2_output_accuracy: 0.9790 - loss: 0.1937 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.6143 - val_loss: 1.9140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x133426bf4a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, {'level1_output': level1_labels_train, 'level2_output': level2_labels_train}, \n",
    "          epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Accuracy for Level 1 (Healthy vs Diabetic): 0.7701149425287356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.65      0.50      0.57        26\n",
      "    Diabetic       0.81      0.89      0.84        61\n",
      "\n",
      "    accuracy                           0.77        87\n",
      "   macro avg       0.73      0.69      0.70        87\n",
      "weighted avg       0.76      0.77      0.76        87\n",
      "\n",
      "Accuracy for Level 2 (Diabetic without neuropathy vs Neuropathic): 0.5081967213114754\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "Diabetic without neuropathy       0.43      0.96      0.59        23\n",
      "                Neuropathic       0.90      0.24      0.38        38\n",
      "\n",
      "                   accuracy                           0.51        61\n",
      "                  macro avg       0.67      0.60      0.48        61\n",
      "               weighted avg       0.72      0.51      0.46        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones con el conjunto de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extraer las predicciones de nivel 1 y nivel 2\n",
    "level1_predictions = (predictions[0] > 0.5).astype(int)\n",
    "level2_predictions = (predictions[1] > 0.5).astype(int)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluación de nivel 1\n",
    "level1_accuracy = accuracy_score(level1_labels_test, level1_predictions)\n",
    "print(f'Accuracy for Level 1 (Healthy vs Diabetic): {level1_accuracy}')\n",
    "print(classification_report(level1_labels_test, level1_predictions, target_names=['Healthy', 'Diabetic']))\n",
    "\n",
    "# Evaluación de nivel 2 (solo para las muestras clasificadas como Diabetic)\n",
    "diabetic_indices = np.where(level1_labels_test == 1)[0]\n",
    "level2_accuracy = accuracy_score(level2_labels_test[diabetic_indices], level2_predictions[diabetic_indices])\n",
    "print(f'Accuracy for Level 2 (Diabetic without neuropathy vs Neuropathic): {level2_accuracy}')\n",
    "print(classification_report(level2_labels_test[diabetic_indices], level2_predictions[diabetic_indices], target_names=['Diabetic without neuropathy', 'Neuropathic']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_json('../data/processed/realData.json', orient='records', lines=True)\n",
    "# Convertir las cadenas en listas de números\n",
    "df['cop_x'] = df['cop_x'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "df['cop_y'] = df['cop_y'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "\n",
    "# Convertir las series de tiempo a arrays numpy\n",
    "X_cop_x = np.array(df['cop_x'].tolist())\n",
    "X_cop_y = np.array(df['cop_y'].tolist())\n",
    "X = np.stack((X_cop_x, X_cop_y), axis=-1)  # Combinar en una sola entrada con 2 canales\n",
    "\n",
    "# Convertir las etiquetas a números\n",
    "label_map = {'Healthy': 0, 'Diabetic': 1, 'Neuropathic': 2}\n",
    "y = df['class'].map(label_map).values\n",
    "\n",
    "# Crear etiquetas para nivel 1 y nivel 2\n",
    "level1_labels = (y > 0).astype(int)  # 0: Healthy, 1: Diabetic (incluye Neuropathic)\n",
    "level2_labels = (y == 2).astype(int)  # 0: Diabetic sin neuropatía, 1: Neuropathic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    act1 = Activation('relu')(bn1)\n",
    "\n",
    "    conv2 = Conv1D(filters, kernel_size, strides=1, padding='same')(act1)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "\n",
    "    if stride != 1:\n",
    "        x = Conv1D(filters, 1, strides=stride, padding='same')(x)\n",
    "    shortcut = Add()([x, bn2])\n",
    "    output = Activation('relu')(shortcut)\n",
    "    return output\n",
    "\n",
    "input_shape = X.shape[1:]\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv1D(64, 7, strides=2, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Salida para nivel 1 (Healthy vs Diabetic)\n",
    "level1_output = Dense(1, activation='sigmoid', name='level1_output')(x)\n",
    "\n",
    "# Salida para nivel 2 (Diabetic sin neuropatía vs Neuropathic)\n",
    "level2_output = Dense(1, activation='sigmoid', name='level2_output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[level1_output, level2_output])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'level1_output': 'binary_crossentropy', 'level2_output': 'binary_crossentropy'},\n",
    "              metrics={'level1_output': 'accuracy', 'level2_output': 'accuracy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - level1_output_accuracy: 0.5668 - level2_output_accuracy: 0.6873 - loss: 1.2816 - val_level1_output_accuracy: 0.9425 - val_level2_output_accuracy: 0.2874 - val_loss: 1.3355\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - level1_output_accuracy: 0.7329 - level2_output_accuracy: 0.7481 - loss: 1.0167 - val_level1_output_accuracy: 0.9770 - val_level2_output_accuracy: 0.0000e+00 - val_loss: 1.3933\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.7924 - level2_output_accuracy: 0.7312 - loss: 1.0011 - val_level1_output_accuracy: 0.8736 - val_level2_output_accuracy: 0.0000e+00 - val_loss: 1.4532\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - level1_output_accuracy: 0.7668 - level2_output_accuracy: 0.7165 - loss: 1.0643 - val_level1_output_accuracy: 0.9195 - val_level2_output_accuracy: 0.0000e+00 - val_loss: 1.4695\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - level1_output_accuracy: 0.7787 - level2_output_accuracy: 0.7662 - loss: 0.9226 - val_level1_output_accuracy: 0.9885 - val_level2_output_accuracy: 0.0000e+00 - val_loss: 1.4448\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - level1_output_accuracy: 0.8468 - level2_output_accuracy: 0.7654 - loss: 0.8978 - val_level1_output_accuracy: 1.0000 - val_level2_output_accuracy: 0.0115 - val_loss: 1.3978\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - level1_output_accuracy: 0.7902 - level2_output_accuracy: 0.7534 - loss: 0.9379 - val_level1_output_accuracy: 0.9885 - val_level2_output_accuracy: 0.0000e+00 - val_loss: 1.4224\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - level1_output_accuracy: 0.7985 - level2_output_accuracy: 0.7340 - loss: 0.9454 - val_level1_output_accuracy: 0.9885 - val_level2_output_accuracy: 0.0115 - val_loss: 1.4614\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - level1_output_accuracy: 0.7765 - level2_output_accuracy: 0.7919 - loss: 0.8739 - val_level1_output_accuracy: 0.9885 - val_level2_output_accuracy: 0.0000e+00 - val_loss: 1.5451\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - level1_output_accuracy: 0.7518 - level2_output_accuracy: 0.7506 - loss: 0.9181 - val_level1_output_accuracy: 1.0000 - val_level2_output_accuracy: 0.0115 - val_loss: 1.4775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2395ad45430>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, {'level1_output': level1_labels, 'level2_output': level2_labels}, \n",
    "          epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - level1_output_accuracy: 0.7378 - level2_output_accuracy: 0.5965 - loss: 1.2156 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5714 - val_loss: 1.3130\n",
      "Epoch 2/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - level1_output_accuracy: 0.8189 - level2_output_accuracy: 0.6451 - loss: 1.0820 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2847\n",
      "Epoch 3/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - level1_output_accuracy: 0.8291 - level2_output_accuracy: 0.7066 - loss: 0.9866 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5714 - val_loss: 1.2900\n",
      "Epoch 4/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - level1_output_accuracy: 0.8403 - level2_output_accuracy: 0.7421 - loss: 0.9397 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.5714 - val_loss: 1.2615\n",
      "Epoch 5/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - level1_output_accuracy: 0.8499 - level2_output_accuracy: 0.7053 - loss: 0.9483 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2721\n",
      "Epoch 6/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - level1_output_accuracy: 0.8263 - level2_output_accuracy: 0.6726 - loss: 0.9348 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5714 - val_loss: 1.2858\n",
      "Epoch 7/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - level1_output_accuracy: 0.8527 - level2_output_accuracy: 0.7303 - loss: 0.9153 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2758\n",
      "Epoch 8/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - level1_output_accuracy: 0.8254 - level2_output_accuracy: 0.7180 - loss: 0.9683 - val_level1_output_accuracy: 0.5714 - val_level2_output_accuracy: 0.5429 - val_loss: 1.3324\n",
      "Epoch 9/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - level1_output_accuracy: 0.8536 - level2_output_accuracy: 0.7123 - loss: 0.9071 - val_level1_output_accuracy: 0.6857 - val_level2_output_accuracy: 0.5286 - val_loss: 1.2896\n",
      "Epoch 10/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - level1_output_accuracy: 0.8417 - level2_output_accuracy: 0.7405 - loss: 0.9107 - val_level1_output_accuracy: 0.6429 - val_level2_output_accuracy: 0.5143 - val_loss: 1.3199\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000023918EC20C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 230ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000023918EC20C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "Accuracy for Level 1 (Healthy vs Diabetic): 0.6551724137931034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.45      0.77      0.57        26\n",
      "    Diabetic       0.86      0.61      0.71        61\n",
      "\n",
      "    accuracy                           0.66        87\n",
      "   macro avg       0.66      0.69      0.64        87\n",
      "weighted avg       0.74      0.66      0.67        87\n",
      "\n",
      "Accuracy for Level 2 (Diabetic without neuropathy vs Neuropathic): 0.39344262295081966\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "Diabetic without neuropathy       0.38      1.00      0.55        23\n",
      "                Neuropathic       1.00      0.03      0.05        38\n",
      "\n",
      "                   accuracy                           0.39        61\n",
      "                  macro avg       0.69      0.51      0.30        61\n",
      "               weighted avg       0.77      0.39      0.24        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear etiquetas para nivel 1 y nivel 2 para el conjunto de prueba\n",
    "level1_labels_train = (y_train > 0).astype(int)\n",
    "level2_labels_train = (y_train == 2).astype(int)\n",
    "\n",
    "level1_labels_test = (y_test > 0).astype(int)\n",
    "level2_labels_test = (y_test == 2).astype(int)\n",
    "\n",
    "# Entrenar el modelo (si no se ha hecho anteriormente)\n",
    "model.fit(X_train, {'level1_output': level1_labels_train, 'level2_output': level2_labels_train}, \n",
    "          epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Hacer predicciones con el conjunto de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extraer las predicciones de nivel 1 y nivel 2\n",
    "level1_predictions = (predictions[0] > 0.5).astype(int)\n",
    "level2_predictions = (predictions[1] > 0.5).astype(int)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluación de nivel 1\n",
    "level1_accuracy = accuracy_score(level1_labels_test, level1_predictions)\n",
    "print(f'Accuracy for Level 1 (Healthy vs Diabetic): {level1_accuracy}')\n",
    "print(classification_report(level1_labels_test, level1_predictions, target_names=['Healthy', 'Diabetic']))\n",
    "\n",
    "# Evaluación de nivel 2 (solo para las muestras clasificadas como Diabetic)\n",
    "diabetic_indices = np.where(level1_labels_test == 1)[0]\n",
    "level2_accuracy = accuracy_score(level2_labels_test[diabetic_indices], level2_predictions[diabetic_indices])\n",
    "print(f'Accuracy for Level 2 (Diabetic without neuropathy vs Neuropathic): {level2_accuracy}')\n",
    "print(classification_report(level2_labels_test[diabetic_indices], level2_predictions[diabetic_indices], target_names=['Diabetic without neuropathy', 'Neuropathic']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - level1_output_accuracy: 0.8414 - level2_output_accuracy: 0.5986 - loss: 1.1788 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5714 - val_loss: 1.3826\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.8403 - level2_output_accuracy: 0.6470 - loss: 1.0671 - val_level1_output_accuracy: 0.7000 - val_level2_output_accuracy: 0.5857 - val_loss: 1.3819\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - level1_output_accuracy: 0.8408 - level2_output_accuracy: 0.7244 - loss: 1.0111 - val_level1_output_accuracy: 0.6857 - val_level2_output_accuracy: 0.5571 - val_loss: 1.3714\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.8730 - level2_output_accuracy: 0.6571 - loss: 0.9978 - val_level1_output_accuracy: 0.6429 - val_level2_output_accuracy: 0.5143 - val_loss: 1.3895\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - level1_output_accuracy: 0.8032 - level2_output_accuracy: 0.6573 - loss: 1.0511 - val_level1_output_accuracy: 0.6000 - val_level2_output_accuracy: 0.5143 - val_loss: 1.4197\n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - level1_output_accuracy: 0.8287 - level2_output_accuracy: 0.7129 - loss: 0.9986 - val_level1_output_accuracy: 0.6143 - val_level2_output_accuracy: 0.5143 - val_loss: 1.4409\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - level1_output_accuracy: 0.8298 - level2_output_accuracy: 0.6782 - loss: 1.0263 - val_level1_output_accuracy: 0.5857 - val_level2_output_accuracy: 0.5286 - val_loss: 1.4262\n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.8549 - level2_output_accuracy: 0.6737 - loss: 0.9782 - val_level1_output_accuracy: 0.6571 - val_level2_output_accuracy: 0.6000 - val_loss: 1.3709\n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - level1_output_accuracy: 0.8313 - level2_output_accuracy: 0.6766 - loss: 1.0022 - val_level1_output_accuracy: 0.5571 - val_level2_output_accuracy: 0.5143 - val_loss: 1.4591\n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - level1_output_accuracy: 0.8617 - level2_output_accuracy: 0.6814 - loss: 0.9784 - val_level1_output_accuracy: 0.7429 - val_level2_output_accuracy: 0.5571 - val_loss: 1.3047\n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.8536 - level2_output_accuracy: 0.6948 - loss: 0.9492 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5143 - val_loss: 1.3999\n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - level1_output_accuracy: 0.8767 - level2_output_accuracy: 0.6568 - loss: 0.9451 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2794\n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.8450 - level2_output_accuracy: 0.6852 - loss: 1.0375 - val_level1_output_accuracy: 0.7714 - val_level2_output_accuracy: 0.5143 - val_loss: 1.3298\n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - level1_output_accuracy: 0.8357 - level2_output_accuracy: 0.7462 - loss: 0.9353 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.5571 - val_loss: 1.2889\n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - level1_output_accuracy: 0.8491 - level2_output_accuracy: 0.7473 - loss: 0.9131 - val_level1_output_accuracy: 0.7857 - val_level2_output_accuracy: 0.5143 - val_loss: 1.3506\n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - level1_output_accuracy: 0.8134 - level2_output_accuracy: 0.7415 - loss: 0.9183 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5286 - val_loss: 1.3708\n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.8814 - level2_output_accuracy: 0.7458 - loss: 0.8658 - val_level1_output_accuracy: 0.7429 - val_level2_output_accuracy: 0.4286 - val_loss: 1.4340\n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.8425 - level2_output_accuracy: 0.7406 - loss: 0.8688 - val_level1_output_accuracy: 0.7286 - val_level2_output_accuracy: 0.4429 - val_loss: 1.3935\n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - level1_output_accuracy: 0.8640 - level2_output_accuracy: 0.7011 - loss: 0.8752 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.4429 - val_loss: 1.3828\n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - level1_output_accuracy: 0.8431 - level2_output_accuracy: 0.7379 - loss: 0.8746 - val_level1_output_accuracy: 0.7571 - val_level2_output_accuracy: 0.4143 - val_loss: 1.4802\n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - level1_output_accuracy: 0.8808 - level2_output_accuracy: 0.7829 - loss: 0.8130 - val_level1_output_accuracy: 0.7429 - val_level2_output_accuracy: 0.4000 - val_loss: 1.5193\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - level1_output_accuracy: 0.8330 - level2_output_accuracy: 0.7961 - loss: 0.8279 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.4429 - val_loss: 1.6048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2390f8482f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_json('../data/processed/realData.json', orient='records', lines=True)\n",
    "\n",
    "# Convertir las cadenas en listas de números\n",
    "df['cop_x'] = df['cop_x'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "df['cop_y'] = df['cop_y'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "\n",
    "# Normalización\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Ajustar y transformar las series de tiempo\n",
    "X_cop_x = np.array(df['cop_x'].tolist())\n",
    "X_cop_y = np.array(df['cop_y'].tolist())\n",
    "\n",
    "X_cop_x = scaler_x.fit_transform(X_cop_x)\n",
    "X_cop_y = scaler_y.fit_transform(X_cop_y)\n",
    "\n",
    "X = np.stack((X_cop_x, X_cop_y), axis=-1)\n",
    "\n",
    "# Convertir las etiquetas a números\n",
    "label_map = {'Healthy': 0, 'Diabetic': 1, 'Neuropathic': 2}\n",
    "y = df['class'].map(label_map).values\n",
    "\n",
    "# Crear etiquetas para nivel 1 y nivel 2\n",
    "level1_labels = (y > 0).astype(int)  # 0: Healthy, 1: Diabetic (incluye Neuropathic)\n",
    "level2_labels = (y == 2).astype(int)  # 0: Diabetic sin neuropatía, 1: Neuropathic\n",
    "\n",
    "# Separar los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "level1_labels_train = (y_train > 0).astype(int)\n",
    "level2_labels_train = (y_train == 2).astype(int)\n",
    "level1_labels_test = (y_test > 0).astype(int)\n",
    "level2_labels_test = (y_test == 2).astype(int)\n",
    "\n",
    "# Construcción del modelo ResNet mejorado\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, dropout_rate=0.3):\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=stride, padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    act1 = Activation('relu')(bn1)\n",
    "    drop1 = Dropout(dropout_rate)(act1)\n",
    "\n",
    "    conv2 = Conv1D(filters, kernel_size, strides=1, padding='same', kernel_regularizer=l2(1e-4))(drop1)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "\n",
    "    if stride != 1:\n",
    "        x = Conv1D(filters, 1, strides=stride, padding='same')(x)\n",
    "    shortcut = Add()([x, bn2])\n",
    "    output = Activation('relu')(shortcut)\n",
    "    return output\n",
    "\n",
    "input_shape = X.shape[1:]\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv1D(64, 7, strides=2, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Salida para nivel 1 (Healthy vs Diabetic)\n",
    "level1_output = Dense(1, activation='sigmoid', name='level1_output')(x)\n",
    "\n",
    "# Salida para nivel 2 (Diabetic sin neuropatía vs Neuropathic)\n",
    "level2_output = Dense(1, activation='sigmoid', name='level2_output')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[level1_output, level2_output])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'level1_output': 'binary_crossentropy', 'level2_output': 'binary_crossentropy'},\n",
    "              metrics={'level1_output': 'accuracy', 'level2_output': 'accuracy'})\n",
    "\n",
    "# Implementar Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, {'level1_output': level1_labels_train, 'level2_output': level2_labels_train}, \n",
    "          epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "Accuracy for Level 1 (Healthy vs Diabetic): 0.6781609195402298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.25      0.04      0.07        26\n",
      "    Diabetic       0.70      0.95      0.81        61\n",
      "\n",
      "    accuracy                           0.68        87\n",
      "   macro avg       0.47      0.49      0.44        87\n",
      "weighted avg       0.56      0.68      0.58        87\n",
      "\n",
      "Accuracy for Level 2 (Diabetic without neuropathy vs Neuropathic): 0.5573770491803278\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "Diabetic without neuropathy       0.46      0.96      0.62        23\n",
      "                Neuropathic       0.92      0.32      0.47        38\n",
      "\n",
      "                   accuracy                           0.56        61\n",
      "                  macro avg       0.69      0.64      0.55        61\n",
      "               weighted avg       0.75      0.56      0.53        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones con el conjunto de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extraer las predicciones de nivel 1 y nivel 2\n",
    "level1_predictions = (predictions[0] > 0.5).astype(int)\n",
    "level2_predictions = (predictions[1] > 0.5).astype(int)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluación de nivel 1\n",
    "level1_accuracy = accuracy_score(level1_labels_test, level1_predictions)\n",
    "print(f'Accuracy for Level 1 (Healthy vs Diabetic): {level1_accuracy}')\n",
    "print(classification_report(level1_labels_test, level1_predictions, target_names=['Healthy', 'Diabetic']))\n",
    "\n",
    "# Evaluación de nivel 2 (solo para las muestras clasificadas como Diabetic)\n",
    "diabetic_indices = np.where(level1_labels_test == 1)[0]\n",
    "level2_accuracy = accuracy_score(level2_labels_test[diabetic_indices], level2_predictions[diabetic_indices])\n",
    "print(f'Accuracy for Level 2 (Diabetic without neuropathy vs Neuropathic): {level2_accuracy}')\n",
    "print(classification_report(level2_labels_test[diabetic_indices], level2_predictions[diabetic_indices], target_names=['Diabetic without neuropathy', 'Neuropathic']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_16012\\983189618.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_model(hp):\n",
    "    input_shape = X.shape[1:]\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Definir los bloques residuales con hiperparámetros\n",
    "    for i in range(hp.Int('num_blocks', 2, 4)):\n",
    "        filters = hp.Int('filters_' + str(i), min_value=32, max_value=128, step=32)\n",
    "        kernel_size = hp.Choice('kernel_size_' + str(i), values=[3, 5, 7])\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    level1_output = Dense(1, activation='sigmoid', name='level1_output')(x)\n",
    "\n",
    "    level2_output = Dense(1, activation='sigmoid', name='level2_output')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[level1_output, level2_output])\n",
    "\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss={'level1_output': 'binary_crossentropy', 'level2_output': 'binary_crossentropy'},\n",
    "                  metrics={'level1_output': 'accuracy', 'level2_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=stride, padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    bn1 = BatchNormalization()(conv1)\n",
    "    act1 = Activation('relu')(bn1)\n",
    "    drop1 = Dropout(0.3)(act1)\n",
    "\n",
    "    conv2 = Conv1D(filters, kernel_size, strides=1, padding='same', kernel_regularizer=l2(1e-4))(drop1)\n",
    "    bn2 = BatchNormalization()(conv2)\n",
    "\n",
    "    if stride != 1:\n",
    "        x = Conv1D(filters, 1, strides=stride, padding='same')(x)\n",
    "    shortcut = Add()([x, bn2])\n",
    "    output = Activation('relu')(shortcut)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_json('../data/processed/realData.json', orient='records', lines=True)\n",
    "\n",
    "\n",
    "# Convertir las cadenas en listas de números (asumiendo que 'cop_x' y 'cop_y' son listas de números)\n",
    "df['cop_x'] = df['cop_x'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "df['cop_y'] = df['cop_y'].apply(lambda x: np.array(eval(x)) if isinstance(x, str) else np.array(x))\n",
    "\n",
    "# Normalización de las series de tiempo\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_cop_x = np.array(df['cop_x'].tolist())\n",
    "X_cop_y = np.array(df['cop_y'].tolist())\n",
    "\n",
    "X_cop_x = scaler_x.fit_transform(X_cop_x)\n",
    "X_cop_y = scaler_y.fit_transform(X_cop_y)\n",
    "\n",
    "X = np.stack((X_cop_x, X_cop_y), axis=-1)\n",
    "\n",
    "# Mapeo de las etiquetas a números (asumiendo clases: 'Healthy', 'Diabetic', 'Neuropathic')\n",
    "label_map = {'Healthy': 0, 'Diabetic': 1, 'Neuropathic': 2}\n",
    "y = df['class'].map(label_map).values\n",
    "\n",
    "# Crear etiquetas para nivel 1 y nivel 2\n",
    "level1_labels = (y > 0).astype(int)  # 0: Healthy, 1: Diabetic (incluye Neuropathic)\n",
    "level2_labels = (y == 2).astype(int)  # 0: Diabetic sin neuropatía, 1: Neuropathic\n",
    "\n",
    "# Separar los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "level1_labels_train = (y_train > 0).astype(int)\n",
    "level2_labels_train = (y_train == 2).astype(int)\n",
    "level1_labels_test = (y_test > 0).astype(int)\n",
    "level2_labels_test = (y_test == 2).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 14s]\n",
      "val_level1_output_accuracy: 0.8142856955528259\n",
      "\n",
      "Best val_level1_output_accuracy So Far: 0.8142856955528259\n",
      "Total elapsed time: 00h 06m 29s\n"
     ]
    }
   ],
   "source": [
    "from kerastuner import Objective, RandomSearch\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import kerastuner as kt\n",
    "\n",
    "# Define la función para construir el modelo\n",
    "def build_model(hp):\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Definir los bloques residuales con hiperparámetros\n",
    "    for i in range(hp.Int('num_blocks', 2, 4)):\n",
    "        filters = hp.Int('filters_' + str(i), min_value=32, max_value=128, step=32)\n",
    "        kernel_size = hp.Choice('kernel_size_' + str(i), values=[3, 5, 7])\n",
    "        x = residual_block(x, filters=filters, kernel_size=kernel_size)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Salida para nivel 1 (Healthy vs Diabetic)\n",
    "    level1_output = Dense(1, activation='sigmoid', name='level1_output')(x)\n",
    "\n",
    "    # Salida para nivel 2 (Diabetic sin neuropatía vs Neuropathic)\n",
    "    level2_output = Dense(1, activation='sigmoid', name='level2_output')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[level1_output, level2_output])\n",
    "\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss={'level1_output': 'binary_crossentropy', 'level2_output': 'binary_crossentropy'},\n",
    "                  metrics={'level1_output': 'accuracy', 'level2_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3):\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "\n",
    "    conv2 = Conv1D(filters, kernel_size, strides=1, padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "\n",
    "    shortcut = Conv1D(filters, 1, strides=1, padding='same')(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Add()([shortcut, conv2])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Configurar el optimizador de búsqueda aleatoria y la métrica\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=Objective('val_level1_output_accuracy', direction='max'),  # Especificar la métrica y dirección de optimización\n",
    "    max_trials=20,  # Número de combinaciones de hiperparámetros a probar\n",
    "    directory='my_dir',\n",
    "    project_name='resnet_tuning'\n",
    ")\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros\n",
    "tuner.search(X_train, {'level1_output': level1_labels_train, 'level2_output': level2_labels_train},\n",
    "             epochs=10,  # Ajusta este valor según sea necesario\n",
    "             validation_split=0.2)  # Ajusta el tamaño de la partición de validación según sea necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Construir el modelo final con los mejores hiperparámetros\n",
    "model = build_model(best_hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 232ms/step - level1_output_accuracy: 0.7666 - level2_output_accuracy: 0.5842 - loss: 1.1875 - val_level1_output_accuracy: 0.7429 - val_level2_output_accuracy: 0.4857 - val_loss: 1.3632\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - level1_output_accuracy: 0.8242 - level2_output_accuracy: 0.6738 - loss: 1.0316 - val_level1_output_accuracy: 0.8571 - val_level2_output_accuracy: 0.5714 - val_loss: 1.3024\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - level1_output_accuracy: 0.8319 - level2_output_accuracy: 0.6681 - loss: 0.9769 - val_level1_output_accuracy: 0.8571 - val_level2_output_accuracy: 0.6571 - val_loss: 1.2991\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - level1_output_accuracy: 0.8425 - level2_output_accuracy: 0.7227 - loss: 0.9257 - val_level1_output_accuracy: 0.6857 - val_level2_output_accuracy: 0.5429 - val_loss: 1.3212\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - level1_output_accuracy: 0.8457 - level2_output_accuracy: 0.6793 - loss: 0.8952 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5714 - val_loss: 1.2660\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - level1_output_accuracy: 0.8468 - level2_output_accuracy: 0.7396 - loss: 0.8356 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6000 - val_loss: 1.2482\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - level1_output_accuracy: 0.8492 - level2_output_accuracy: 0.7240 - loss: 0.8585 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.6000 - val_loss: 1.2575\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.8502 - level2_output_accuracy: 0.7558 - loss: 0.8147 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.6000 - val_loss: 1.2604\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - level1_output_accuracy: 0.8429 - level2_output_accuracy: 0.7255 - loss: 0.8531 - val_level1_output_accuracy: 0.6857 - val_level2_output_accuracy: 0.5714 - val_loss: 1.2621\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.8480 - level2_output_accuracy: 0.7684 - loss: 0.7934 - val_level1_output_accuracy: 0.8571 - val_level2_output_accuracy: 0.6000 - val_loss: 1.2311\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.8562 - level2_output_accuracy: 0.8413 - loss: 0.6944 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5429 - val_loss: 1.2008\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - level1_output_accuracy: 0.8667 - level2_output_accuracy: 0.8270 - loss: 0.7223 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5714 - val_loss: 1.2958\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - level1_output_accuracy: 0.8645 - level2_output_accuracy: 0.8438 - loss: 0.6932 - val_level1_output_accuracy: 0.5714 - val_level2_output_accuracy: 0.6286 - val_loss: 1.4664\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.8515 - level2_output_accuracy: 0.8454 - loss: 0.6712 - val_level1_output_accuracy: 0.5143 - val_level2_output_accuracy: 0.5714 - val_loss: 1.4761\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.8846 - level2_output_accuracy: 0.8559 - loss: 0.5832 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6000 - val_loss: 1.5265\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - level1_output_accuracy: 0.8973 - level2_output_accuracy: 0.8478 - loss: 0.5773 - val_level1_output_accuracy: 0.4857 - val_level2_output_accuracy: 0.5714 - val_loss: 1.5779\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.8949 - level2_output_accuracy: 0.8836 - loss: 0.5342 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5714 - val_loss: 1.3337\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - level1_output_accuracy: 0.8956 - level2_output_accuracy: 0.9063 - loss: 0.4919 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.5429 - val_loss: 1.3891\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - level1_output_accuracy: 0.9315 - level2_output_accuracy: 0.9383 - loss: 0.4180 - val_level1_output_accuracy: 0.5429 - val_level2_output_accuracy: 0.5429 - val_loss: 1.9421\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - level1_output_accuracy: 0.8925 - level2_output_accuracy: 0.9329 - loss: 0.4599 - val_level1_output_accuracy: 0.6571 - val_level2_output_accuracy: 0.5714 - val_loss: 1.9436\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - level1_output_accuracy: 0.9162 - level2_output_accuracy: 0.9526 - loss: 0.4202 - val_level1_output_accuracy: 0.6286 - val_level2_output_accuracy: 0.5714 - val_loss: 1.5963\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.9392 - level2_output_accuracy: 0.9186 - loss: 0.3490 - val_level1_output_accuracy: 0.5429 - val_level2_output_accuracy: 0.4571 - val_loss: 1.8701\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - level1_output_accuracy: 0.9569 - level2_output_accuracy: 0.9808 - loss: 0.2712 - val_level1_output_accuracy: 0.8286 - val_level2_output_accuracy: 0.5143 - val_loss: 1.4629\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - level1_output_accuracy: 0.9639 - level2_output_accuracy: 0.9652 - loss: 0.2792 - val_level1_output_accuracy: 0.7143 - val_level2_output_accuracy: 0.5714 - val_loss: 1.6887\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - level1_output_accuracy: 0.9130 - level2_output_accuracy: 0.9399 - loss: 0.3511 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.6286 - val_loss: 1.9272\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - level1_output_accuracy: 0.9653 - level2_output_accuracy: 0.9423 - loss: 0.2990 - val_level1_output_accuracy: 0.8000 - val_level2_output_accuracy: 0.5714 - val_loss: 2.7728\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Entrenar el modelo final\n",
    "history = model.fit(X_train, {'level1_output': level1_labels_train, 'level2_output': level2_labels_train},\n",
    "                    epochs=100,  # Ajusta el número de épocas según sea necesario\n",
    "                    validation_split=0.1,  # Ajusta el tamaño de la partición de validación según sea necesario\n",
    "                    callbacks=[EarlyStopping(patience=15, restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - level1_output_accuracy: 0.7529 - level2_output_accuracy: 0.6263 - loss: 1.2172\n",
      "\n",
      "Evaluation results:\n",
      "loss: 1.2040011882781982\n",
      "compile_metrics: 0.7011494040489197\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate(X_test, {'level1_output': level1_labels_test, 'level2_output': level2_labels_test})\n",
    "print(\"\\nEvaluation results:\")\n",
    "for metric, value in zip(model.metrics_names, eval_results):\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 01s]\n",
      "\n",
      "Best val_acc So Far: None\n",
      "Total elapsed time: 00h 00m 03s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |2                 |num_blocks\n",
      "128               |128               |filters_0\n",
      "32                |32                |filters_1\n",
      "64                |32                |filters_2\n",
      "32                |128               |filters_3\n",
      "7                 |3                 |kernel_size_0\n",
      "7                 |5                 |kernel_size_1\n",
      "7                 |7                 |kernel_size_2\n",
      "5                 |3                 |kernel_size_3\n",
      "0.0001            |0.001             |learning_rate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 232, in _build_and_fit_model\n",
      "    model = self._try_build(hp)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 164, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 155, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 123, in train_model\n",
      "    outputs = model(X_train_tensor)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 46, in forward\n",
      "    out = self.layers(out)\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 83, in forward\n",
      "    out += identity\n",
      "RuntimeError: The size of tensor a (42) must match the size of tensor b (50) at non-singleton dimension 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 232, in _build_and_fit_model\n    model = self._try_build(hp)\n            ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 164, in _try_build\n    model = self._build_hypermodel(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 155, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 123, in train_model\n    outputs = model(X_train_tensor)\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 46, in forward\n    out = self.layers(out)\n          ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n    input = module(input)\n            ^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 83, in forward\n    out += identity\nRuntimeError: The size of tensor a (42) must match the size of tensor b (50) at non-singleton dimension 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 150\u001b[0m\n\u001b[0;32m    141\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[0;32m    142\u001b[0m     train_model,\n\u001b[0;32m    143\u001b[0m     objective\u001b[38;5;241m=\u001b[39mkt\u001b[38;5;241m.\u001b[39mObjective(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m),  \u001b[38;5;66;03m# Especificar la métrica y dirección de optimización\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet_tuning\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    147\u001b[0m )\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Realizar la búsqueda de hiperparámetros\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ajusta este valor según sea necesario\u001b[39;49;00m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ajusta el tamaño del lote según sea necesario\u001b[39;49;00m\n\u001b[0;32m    153\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[1;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[0;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    549\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 232, in _build_and_fit_model\n    model = self._try_build(hp)\n            ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 164, in _try_build\n    model = self._build_hypermodel(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 155, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 123, in train_model\n    outputs = model(X_train_tensor)\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 46, in forward\n    out = self.layers(out)\n          ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n    input = module(input)\n            ^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_19664\\1081497777.py\", line 83, in forward\n    out += identity\nRuntimeError: The size of tensor a (42) must match the size of tensor b (50) at non-singleton dimension 2\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
